{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc93a5a0",
   "metadata": {},
   "source": [
    "# Face Mask Detection Using Convolutional Neural Network(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438ec59",
   "metadata": {},
   "source": [
    "<img src=\"cnn.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3aaa79",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\">Convolutional Neural Network is a type of deep learning algorithm commonly used in image processing tasks such as image classification, object detection, segmentation, and more.\n",
    "The main idea behind CNNs is to learn spatial hierarchies of features from the input image. It consists of multiple layers, each layer performing a specific operation such as convolution, pooling, and activation.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696f6a5",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01652915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f9dc9",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5414fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Dataset'\n",
    "img_class = ['without_mask', 'with_mask']\n",
    "labels = {'without_mask': 0, 'with_mask': 1}\n",
    "img_size = 100\n",
    "numOfCategory = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8cd40",
   "metadata": {},
   "source": [
    "### Declaring variables to store <b>Data</b> and <b>Target</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe23128",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "target = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74ae5b",
   "metadata": {},
   "source": [
    "### Accessing the dataset to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eachClass in img_class:\n",
    "    folder_path = os.path.join(data_path, eachClass)\n",
    "    img_names = os.listdir(folder_path)\n",
    "    \n",
    "    for img_name in img_names:\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "          \n",
    "        try:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray, (img_size, img_size))\n",
    "            \n",
    "            data.append(resized)\n",
    "            target.append(labels[eachClass])\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(\"Exception: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379010af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62130b8",
   "metadata": {},
   "source": [
    "### Convert Data & Target into Array + Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0efeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "readyData = np.array(data)/255.0\n",
    "readyData = readyData.reshape(len(readyData), img_size, img_size, 1)\n",
    "readyTarget = np.array(target)\n",
    "readyTarget = np_utils.to_categorical(readyTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dfa96",
   "metadata": {},
   "source": [
    "### Export Data & Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data', readyData)\n",
    "np.save('target', readyTargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d384472",
   "metadata": {},
   "source": [
    "## Part 2 - Model Training \n",
    "### Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = np.load('data.npy')\n",
    "trainTarget = np.load('target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec800354",
   "metadata": {},
   "source": [
    "### Splitting data into training set and testing set\n",
    "#### Training data: The training dataset is the data used to train a machine learning model.\n",
    "#### Testing data: The testing dataset is used to evaluate the performance of a trained machine learning model.\n",
    "#### Validation data: The validation dataset is used to tune the hyperparameters of a machine learning model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bde39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(trainData, trainTarget, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49948846",
   "metadata": {},
   "source": [
    "### Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_size, img_size, 1)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(numOfCategory, activation='softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc96b9d",
   "metadata": {},
   "source": [
    "### Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9614c69",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a7b7f",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825ab0d",
   "metadata": {},
   "source": [
    "### Plot the training and validation accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac01d06",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;\"><b>To check for overfitting by comparing the training and validation loss and accuracy</b> <br>If the training loss and accuracy continue to improve while the validation loss and accuracy start to plateau or even decrease, it may indicate that the model is overfitting the training data.</p>\n",
    "<img src=\"accuracyGraph.jpg\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e894a36",
   "metadata": {},
   "source": [
    "### Construct Confusion Matrix for Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637450c",
   "metadata": {},
   "source": [
    "<img src=\"confusionMatrix.jpg\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11478d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c239ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"Accuracy: \", np.format_float_positional(accuracy, precision=4))\n",
    "print(\"Precision: \", np.format_float_positional(precision, precision=4))\n",
    "print(\"Recall: \", np.format_float_positional(recall, precision=4))\n",
    "print(\"F1_Score: \", np.format_float_positional(f1_score, precision=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e88208",
   "metadata": {},
   "source": [
    "### Export Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a29385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9948f",
   "metadata": {},
   "source": [
    "## Part 3 - Model Deployment & Application "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877d577",
   "metadata": {},
   "source": [
    "### Load the saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c401a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ba5ea",
   "metadata": {},
   "source": [
    "### Define the output of prediction classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb379feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Masked', 'No Mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75ac70",
   "metadata": {},
   "source": [
    "### Deploy using Real-Time Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4161a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Testing using real-time video\n",
    "import pygame\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize Pygame mixer for sound\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Load the alarm sound file\n",
    "sound = pygame.mixer.Sound(\"warn.mp3\")\n",
    "# define the gap of alarm in seconds\n",
    "time_gap = 2\n",
    "last_alarm = time.time()\n",
    "# Initialize video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set font for displaying accuracy\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "thickness = 2\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # Loop over all detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face ROI\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize the face ROI to match the input size of the model\n",
    "        face_roi_resized = cv2.resize(face_roi, (100, 100))\n",
    "\n",
    "        # Normalize the face ROI to have pixel values between 0 and 1\n",
    "        face_roi_norm = face_roi_resized / 255.0\n",
    "\n",
    "        # Reshape the face ROI to match the input shape of the model\n",
    "        face_roi_norm_reshaped = np.reshape(face_roi_norm, (1, 100, 100, 1))\n",
    "\n",
    "        # Make a prediction on the face ROI using the loaded model\n",
    "        prediction = model.predict(face_roi_norm_reshaped)\n",
    "\n",
    "        # Get the predicted class label\n",
    "        predicted_class = np.argmax(prediction)\n",
    "\n",
    "        # Get the predicted class name\n",
    "        if predicted_class == 1:\n",
    "            predicted_class_name = 'Mask'\n",
    "            color = [0, 255, 0]\n",
    "        else:\n",
    "            predicted_class_name = 'No Mask'\n",
    "            color = [0, 0, 255]\n",
    "            \n",
    "        # Get the predicted class probability\n",
    "        predicted_prob = prediction[0][predicted_class]   \n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "        # Put the predicted class and accuracy on the rectangleq\n",
    "        cv2.putText(frame, predicted_class_name + ' ' + str(round(predicted_prob * 100, 2)) + '%', (x, y-10), font, font_scale, color, thickness)\n",
    "\n",
    "        # If no mask is detected and alarm is not already on, activate the alarm\n",
    "        if predicted_class == 0 and time.time() - last_alarm > time_gap:\n",
    "            sound.play()\n",
    "            last_alarm = time.time()\n",
    "            \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Mask Detection', frame)\n",
    "\n",
    "    # Wait for 'q' key to be pressed to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d50b8",
   "metadata": {},
   "source": [
    "### Deploy using Image\n",
    "<br>\n",
    "<div style=\"display:flex; align-content: center;\">\n",
    "<img src=\"noMaskOutput.jpg\" style=\"width:350px; display:inline-block; \">\n",
    "<img src=\"maskOutput.jpg\" style=\"width:350px; display:inline-block;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing using image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "inputImg = cv2.imread('BlackpinkNoMask.jpg') #BlackpinkNoMask.jpg\n",
    "# Load the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "gray = cv2.cvtColor(inputImg, cv2.COLOR_BGR2GRAY)\n",
    "# Detect faces in the frame\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "# Loop over all detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    # Extract the face ROI\n",
    "    face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize the face ROI to match the input size of the model\n",
    "    face_roi_resized = cv2.resize(face_roi, (100, 100))\n",
    "\n",
    "    # Normalize the face ROI to have pixel values between 0 and 1\n",
    "    face_roi_norm = face_roi_resized / 255.0\n",
    "\n",
    "    # Reshape the face ROI to match the input shape of the model\n",
    "    face_roi_norm_reshaped = np.reshape(face_roi_norm, (1, 100, 100, 1))\n",
    "\n",
    "    # Make a prediction on the face ROI using the loaded model\n",
    "    prediction = model.predict(face_roi_norm_reshaped)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Get the predicted class name\n",
    "    if predicted_class == 1:\n",
    "        predicted_class_name = 'Mask'\n",
    "        color = [0, 255, 0]\n",
    "    else:\n",
    "        predicted_class_name = 'No Mask'\n",
    "        color = [0, 0, 255]\n",
    "            \n",
    "    # Get the predicted class probability\n",
    "    predicted_prob = prediction[0][predicted_class]   \n",
    "        \n",
    "    # Draw a rectangle around the face\n",
    "    cv2.rectangle(inputImg, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "    # Put the predicted class and accuracy on the rectangleq\n",
    "    cv2.putText(inputImg, predicted_class_name + ' ' + str(round(predicted_prob * 100, 2)) + '%', (x, y-10), font, font_scale, color, thickness)\n",
    "\n",
    "# Display the resulting frame\n",
    "cv2.imshow('Mask Detection', inputImg)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec89f2f6",
   "metadata": {},
   "source": [
    "### Deployment with User Interface - Upload Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f586b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model_CNN.h5')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Face Mask Detection\")\n",
    "\n",
    "canvas = tk.Canvas(root, width=1000, height=700)\n",
    "canvas.pack()\n",
    "\n",
    "# Store a reference to the PhotoImage object\n",
    "photo_img = None\n",
    "\n",
    "# Set font for displaying accuracy\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "thickness = 2\n",
    "\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    img = cv2.imread(file_path)\n",
    "    # Load the face cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # Loop over all detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face ROI\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize the face ROI to match the input size of the model\n",
    "        face_roi_resized = cv2.resize(face_roi, (100, 100))\n",
    "\n",
    "        # Normalize the face ROI to have pixel values between 0 and 1\n",
    "        face_roi_norm = face_roi_resized / 255.0\n",
    "\n",
    "        # Reshape the face ROI to match the input shape of the model\n",
    "        face_roi_norm_reshaped = np.reshape(face_roi_norm, (1, 100, 100, 1))\n",
    "\n",
    "        # Make a prediction on the face ROI using the loaded model\n",
    "        prediction = model.predict(face_roi_norm_reshaped)\n",
    "\n",
    "        # Get the predicted class label\n",
    "        predicted_class = np.argmax(prediction)\n",
    "\n",
    "        # Get the predicted class name\n",
    "        if predicted_class == 1:\n",
    "            predicted_class_name = 'Mask'\n",
    "            color = [0, 255, 0]\n",
    "        else:\n",
    "            predicted_class_name = 'No Mask'\n",
    "            color = [0, 0, 255]\n",
    "            \n",
    "        # Get the predicted class probability\n",
    "        predicted_prob = prediction[0][predicted_class]   \n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "        # Put the predicted class and accuracy on the rectangle\n",
    "        cv2.putText(img, predicted_class_name + ' ' + str(round(predicted_prob * 100, 2)) + '%', (x, y-10), font, font_scale, color, thickness)\n",
    "\n",
    " # Convert the BGR image to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    global photo_img\n",
    "   \n",
    "    img = Image.fromarray(img)\n",
    "    photo_img = ImageTk.PhotoImage(img)\n",
    "    canvas.create_image(0, 0, anchor=tk.NW, image=photo_img)\n",
    "\n",
    "\n",
    "btn_upload = tk.Button(root, text='Upload Image', command=upload_image)\n",
    "btn_upload.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a25b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
